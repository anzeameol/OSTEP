<center><font size = 15>OSTEP Notes</font></center>
<p align = "right"><font size = 5>by Nemo</font></p>
<p align = "right">2023.7.26</p>

### 进程
进程：程序的抽象    
进程状态：创建，运行（running），就绪（ready），阻塞（blocked），终止  
```c
#include<unistd.h> //need to include

fork() //create a child process

#include<sys/wait.h>
wait() //父进程等待子进程结束

exec()
/*会从可执行程序中加载代码和静态数据，并用它覆写自己的代码段（以及静态数据），堆、栈及其他内存空间也会被重新初始化。然后操作系统就执行该程序，将参数通过argv传递给该进程。因此，它并没有创建新进程，而是直接将当前运行的程序替换为不同的运行程序。对exec()的成功调用永远不会返回。*/

getpid() //获取进程pid
```

### 进程调度
#### 算法
考量：
1. 响应时间：从任务到达系统到首次运行的时间
2. 周转时间：任务完成时间减去任务到达系统的时间
- FIFO/FCFS 先进先出，平均响应时间和平均周转时间都不太行
- SJF 最短任务优先：周转时间短，响应时间没有保证
- STCF 最短完成时间优先：SJF的升级版，周转时间更短
- RR 轮转：划分为多个时间片，轮流执行，响应时间短，周转时间很长。bug：I/O
- MLFQ 多级反馈队列：存在许多独立的、不同优先级的队列，每个队列中有多个工作；优先处理高优先级队列中的工作，同一队列中采用轮转；工作优先级会变化。变化的算法有很多，基本的如：
  1. 工作进入系统时，放在最高优先级（最上层队列）。
  2. 工作用完整个时间片后，降低其优先级（移入下一个队列）。
  3. 如果工作在其时间片以内主动释放 CPU，
则优先级不变。
很好地结合了轮转、STCF的优点且可以应对I/O  
bug：
  1. 饥饿：太多交互型工作，长工作无法得到cpu
改进：
  1. 提升优先级
  2. 一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）
- 彩票调度：利用随机性（优点：轻量，只需要记录很少状态；快），实现：链表
```c
while (current) { 
    counter = counter + current->tickets; 
    if (counter > winner) 
        break; // found the winner 
    current = current->next; 
}
```
- 步长调度：每个进程有不同的步长，被执行一次加一个步长，系统优先执行步长较小的进程

#### 处理顺序
假设在进程表中有两个进程A、B，从A切换到进程B：  
1. 时钟中断
2. 转向内核模式
3. 跳到中断处理程序
4. 处理陷阱
5. 调用switch()例程
- 将寄存器（A）保存到进程结构（A）（包括基址/界限）
- 从进程结构（B）恢复寄存器（B）（包括基址/界限）
6. 从陷阱返回（进入 B）


### 多处理器调度
#### 问题：
1. 缓存一致性问题：比如3级cache往往是共享的，而1级cache往往是独有的，独有的cache和共享cache之间可能就会存在数据的不一致性  
解决方法（其一）：总线窥探（bus snooping）每个缓存监听和链接所有缓存和内存的总线
2. 跨cpu访问：如删除共享数据时，有可能会同时删除相同的数据  
解决：加锁，访问开始时加锁，结束时解锁
3. 缓存亲和度：一个进程在某个 CPU 上运行时，会在该 CPU 的缓存中维护许多状态。下次该进程在相同CPU上运行时，由于缓存中的数据而执行得更快。相反，在不同的CPU上执行，会由于需要重新加载数据而很慢（好在硬件保证的缓存一致性可以保证正确执行）。因此多处理器调度应该考虑到这种缓存亲和性，并尽可能将进程保持在同一个CPU上。

#### 调度方案
- SQMS 单队列多处理器调度：把所有需要调度的工作放入一个单独的队列中，每个cpu选择合适的工作
bug：
  1. 加锁耗时大，且此耗时会随着cpu数增加而增加
  2. 如果工作数量大于cpu数量，每个工作依次执行一个时间片，cpu会一直执行不同的工作，一件工作在不同的cpu上执行，造成缓存亲和度较低。可以通过一些调度策略来缓解
- MQMS 多队列调度：每个cpu有自己的调度队列，工作进入操作系统之后，由操作系统决定应该将工作放入哪个队列。优点：可扩展性高，缓存亲和度高；bug：负载不均。解决：迁移，迁移算法是需要细心设计的，经典的有工作窃取（work stealing）

### 抽象地址空间
> 我们写的c程序中打印的指针、看到的文件中的地址都是虚拟地址，而不是真正的物理地址；只有操作系统（和硬件）才知道物理地址。如果我们能够得知物理地址的话，会造成很大的安全性的问题
> malloc之后不调用free有时是没问题的，比如你的程序很短，这个进程很快就退出，那么操作系统将清理其分配的所有页面，因此不会发生内存泄露；
//内存泄漏：申请内存但没释放  
如果你编写一个长期运行的服务器（例如 Web 服务器或数据库管理系统，它永远不会退出），泄露内存就是很大的问题，最终会导致应用程序在内存不足时崩溃。
> 基于硬件的动态重定位：在运行过程中，通过硬件将虚拟地址转化为真实的物理地址
> 界限（限制）寄存器：提供访问保护，如果进程需要访问超过这个界限或者为负数的虚拟地址，CPU 将触发异常，进程最终可能被终止。
> 负责地址转换的部分：MMU 内存管理单元

### 页表
#### 混合分页和分段
分段的话调度不方便（因为每个段的大小不一样），分页的话过小或者过大的页都会造成问题（过小：页表过大；过大：页内内存浪费），所以采用混合方法：  
多个页表，如代码段、堆、栈各自对应一个页表
基址寄存器--->保存该段的页表的物理地址
界限寄存器--->指示页表的结尾（即它有多少有效页）
用这种方法，栈和堆之间未分配的页不再占用页表中的空间（仅将其标记为无效）

#### 多级页表
相当于页表嵌套页表  
这样可以节省很多内存空间，但是每次TLB未命中则需要多次访问内存

### 并发
进程中的多线程  
原因：现代计算机普遍多核，即拥有多个cpu，多线程能提高程序的运行速度  
- 每个线程有自己的一组用于计算的寄存器
- 从运行一个线程（T1）切换到另一个线程（T2）时，必定发生上下文切换（context switch）。  
//进程：进程控制块（Process Control Block，PCB）  
//线程：线程控制块（Thread Control Block，TCB）
- 线程之间的地址空间是共享的，这是难以处理的，因为这代表全局数据是共享的，线程的调度（不可控）可能会使它们出现计算错误

#### 线程创建
```c
#include <pthread.h>  //pthread库

int pthread_create(
  pthread_t * thread, 
  const pthread_attr_t * attr, 
  void * (*start_routine)(void*), 
  void * arg);

pthread_join(pthread_t thread, void * ret);
```

#### 锁
```c
/*锁*/
int pthread_mutex_lock(pthread_mutex_t *mutex); 
int pthread_mutex_unlock(pthread_mutex_t *mutex);
```
目的：为了让共享变量不能被多个线程同时访问  
因此在临界空间（访问共享变量），一个线程访问时要上锁，访问结束再解锁  
生产锁的要点：基于指令的原子性，可以通过硬件支持  
基于锁：并发计数器、并发链表、并发队列、并发散列表

#### 条件变量
```c
/*条件变量*/
int pthread_cond_wait(pthread_cond_t *cond,pthread_mutex_t *mutex); 
/*wait调用时，要保证mutex应该是在上锁状态
wait会释放锁，并让调用它的线程休眠
当另外某个线程发信号给它（signal）后，它被唤醒，再获取锁，然后返回给调用者*/

int pthread_cond_signal(pthread_cond_t *cond);
/*调用signal的线程也要保证获取锁之后再调用signal*/

//调用 signal 和 wait 时要持有锁
/*原因：我认为应该是避免出现死睡眠
条件变量要配合状态变量一同使用，如果在wait调用之前（此时状态变量已被检查过），线程被调度走，然后其他线程调用signal，但没有任何进程在wait状态，然后其他线程退出，又回到此线程，调用wait进入死睡眠*/
```
线程可以使用条件变量（condition variable），来等待一个条件变成真。条件变量是一个显式队列，当某些执行状态（即条件，condition）不满足时，线程可以把自己加入队列，等
待（waiting）该条件。另外某个线程，当它改变了上述状态时，就可以唤醒一个或者多个等待线程（通过在该条件上发信号），让它们继续执行。



##### 生产者/消费者（有界缓冲区）问题
多个条件变量  
while代替if

#### 信号量
信号量是有一个整数值的对象，可以用两个函数来操作它。  
在 POSIX 标准中，是sem_wait()和 sem_post()
```c
sem_t m; 

sem_wait(&m); 
/*调用时会将m减1，然后判断：如果m大于等于0，那么立即返回，否则挂起，直到之后的post操作
如果多个线程调用sem_wait，那么会进入一个等待队列
post操作会让等待序列首位的wait调用直接返回*/

sem_post(&m); 
/*无条件增加信号量的值，如果有等待线程，
唤醒其中一个*/

//当信号量的值为负数时，这个值就是等待线程的个数
```
信号量可以用于：
#### 实现锁
```c
sem_t m; 
sem_init(&m, 0, 1); 
sem_wait(&m); 
// critical section here 
sem_post(&m); 
```
#### 实现条件变量
```c
/*示例*/
sem_t s; 

void *child(void *arg) { 
  printf("child\n"); 
  sem_post(&s); // signal here: child is done 
  return NULL; 
} 

int main(int argc, char *argv[]) { 
  sem_init(&s, 0, 0);
  printf("parent: begin\n"); 
  pthread_t c; 
  pthread_create(c, NULL, child, NULL); 
  sem_wait(&s); // wait here for child 
  printf("parent: end\n"); 
  return 0; 
} 
```
#### 生产者/消费者（有界缓冲区）问题
```c
sem_t empty;
sem_t full;
sem_t mutex;

void *producer(void *arg)
{
    int i;
    for (i = 0; i < loops; i++)
    {
        sem_wait(&empty); // line p1
        sem_wait(&mutex); // line p1.5 (MOVED MUTEX HERE...)
        put(i);           // line p2
        sem_post(&mutex); // line p2.5 (... AND HERE)
        sem_post(&full);  // line p3
    }
}

void *consumer(void *arg)
{
    int i;
    for (i = 0; i < loops; i++)
    {
        sem_wait(&full);  // line c1
        sem_wait(&mutex); // line c1.5 (MOVED MUTEX HERE...)
        int tmp = get();  // line c2
        sem_post(&mutex); // line c2.5 (... AND HERE)
        sem_post(&empty); // line c3
        printf("%d\n", tmp);
    }
}

int main(int argc, char *argv[])
{
    // ...
    sem_init(&empty, 0, MAX); // MAX buffers are empty to begin with...
    sem_init(&full, 0, 0);    // ... and 0 are full
    sem_init(&mutex, 0, 1);   // mutex=1 because it is a lock
    // ...
}
```
#### 读者—写者锁（reader-writer lock）
用于并发链表

#### 哲学家就餐问题
这个问题的基本情况是：假定有5位“哲学家”围着一个圆桌。每两位哲学家之间有一把餐叉（一共5把）。哲学家有时要思考一会，不需要餐叉；有时又要就餐。而一位哲学家只有同时拿到了左手边和右手边的两把餐叉，才能吃到东西。
每个哲学家的基本循环
```c
while (1)
{
    think();
    getforks();
    eat();
    putforks();
}
```
关键的挑战就是如何实现 getforks()和 putforks()函数，保证没有死锁，没有哲学家饿死，并且并发度更高（尽可能让更多哲学家同时吃东西）。  
解决：
5个信号量sem_t forks[5]
```c
int left(int p) { return p; }
int right(int p) { return (p + 1) % 5; }

void getforks()
{
    if (p == 4)
    {
        sem_wait(forks[right(p)]);
        sem_wait(forks[left(p)]);
    }
    else
    {
        sem_wait(forks[left(p)]);
        sem_wait(forks[right(p)]);
    }
}

void putforks()
{
    sem_post(forks[left(p)]);
    sem_post(forks[right(p)]);
}
```

### 常见并发问题
- 死锁：
死锁的产生需要如下 4 个条件：
1. 互斥：线程对于需要的资源进行互斥的访问（例如一个线程抢到锁）
2. 持有并等待：线程持有了资源（例如已将持有的锁），同时又在等待其他资源（例如，需要获得的锁）
3. 非抢占：线程获得的资源（例如锁），不能被抢占
4. 循环等待：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的
- 非死锁
  - 违反原子性缺陷：代码段本意是原子的，但在执行中并没有强制实现原子性；解决：加锁
  - 错误顺序缺陷：两个内存访问的预期顺序被打破了；解决：条件变量

> 预防死锁：偏序（确定锁的获取顺序）、原子地抢锁、通过调度避免死锁（但不广泛）、死锁检测和恢复技术

### 基于事件的并发
select()  
poll()
//......

### I/O设备
#### 操作系统与设备的交互
轮询方式：
1. while (STATUS == BUSY) ; // wait until device is not busy 
2. Write data to DATA register 
3. Write command to COMMAND register 
 (Doing so starts the device and executes the command) 
4. while (STATUS == BUSY) 
 ; // wait until device is done with your request 
坏处：低效，轮询会浪费大量cpu时间

中断方式：
CPU 不再需要不断轮询设备，而是向设备发出一个请求，然后就可以让对应进程睡眠，切换执行其他任务。  
当设备完成了自身操作，会抛出一个硬件中断，引发 CPU 跳
转执行操作系统预先定义好的中断服务例程（Interrupt Service Routine，ISR），或更为简单的中断处理程序（interrupt handler）。中断处理程序是一小段操作系统代码，它会结束之前的请求（比如从设备读取到了数据或者错误码）并且唤醒等待 I/O 的进程继续执行。  
优势：高效利用cpu  
局限：因为处理中断、进程的切换会带来一定的代价，如果设备的请求十分快，反而会使系统变慢

混合方式：
先尝试轮询一小段时间，如果设备没有完成操作，此时再使用中断。  
这种两阶段（two-phased）的办法可以实现两种方法的好处。

#### DMA（Direct Memory Access）
相当于一个额外控制与设备交互的单元  
为了能够将数据传送给设备，操作系统会通过编程告诉 DMA 引擎数据在内存的位置，要拷贝的大小以及要拷贝到哪个设备。在此之后，操作系统就可以处理其他请求了。当 DMA 的任务完成后，DMA 控制器会抛出一个中断来告诉操作系统自己已经完成数据传输。

#### 设备交互的方法
1. 明确的I/O 指令
2. 内存映射I/O（memory-mapped I/O）  
硬件将设备寄存器作为内存地址提供。当需要访问设备寄存器时，操作系统装载（读取）或者存入（写入）到该内存地址；然后硬件会将装载/存入转移到设备上，而不是物理内存

#### 与不同设备都能进行交互
抽象：设备驱动程序  
e.g. 系统向通用块设备层发送读写请求即可，块设备层会将这些请求路由给对应的设备驱动，然后设备驱动来完成真正的底层操作。

### 磁盘
读写数据花费的时间：寻道时间、旋转等待时间、传输数据时间

外圈磁道通常比内圈磁道具有更多扇区，这是几何结构的结果。那里空间更多。这些磁道通常被称为多区域（multi-zoned）磁盘驱动器，其中磁盘被组织成多个区域，区域是表面上连续的一组磁道。每个区域
每个磁道具有相同的扇区数量，并且外圈区域具有比内圈区域更多的扇区。

磁盘驱动器具有磁道缓冲区（track buffer），类似cache

磁盘的调度：给定一组 I/O 请求，磁盘调度程序检查请求并决定下一个要调度的请求； 
磁盘调度程序一般遵循 SJF（最短任务优先）的原则，因为往往可以很好地估计每个磁盘请求需要多少时间
算法：SSTF（最短寻道时间优先），NBF（最近块优先），SCAN（电梯算法），SPTF（最短定位时间优先）

### 廉价冗余磁盘阵列（RAID）
原因：避免磁盘出现故障造成数据丢失  

评估RAID：
- 容量
- 可靠性
- 性能
  - 单请求延迟
  - 稳态吞吐量（顺序工作负载和随机工作负载）

#### RAID 0
- 条带化  
- 没有冗余
- 以轮转方式将磁盘阵列的块分布在磁盘上；这样在对数组的连续块进行请求时，从阵列中获取最大的并行性
- 评估
  - 容量顶级（没有冗余）；
  - 可靠性：最糟糕（任何磁盘故障都会导致数据丢失）；
  - 性能：顶级
    - 单块请求的延迟应该与单个磁盘的延迟几乎相同：RAID-0可以简单地将该请求重定向到其磁盘之一
    - 从稳态吞吐量的角度来看
      - 顺序工作负载：吞吐量等于 N（磁盘数量）乘以 S（单个磁盘的顺序带宽）
      - 随机工作负载：吞吐量等于 N（磁盘数量）乘以 R（单个磁盘的随机带宽）

#### RAID 1
- 镜像
- 生成每个块的多个副本，每个副本放在单独的磁盘上
- 读取：任意选择一个副本读取；写入：写所有的副本（可以并行写入）
- 评估
  - 容量：糟糕，N/k，k为副本数
  - 可靠性：良好
  - 性能：还行
    - 单个请求延迟：
      - 读取：与单个磁盘上的延迟相同
      - 写入：并行写入，但必须等待所有副本的写入完成，所以取所有写入中最差的时间，比写入单个磁盘略高
    - 从稳态吞吐量的角度来看
      - 顺序工作负载：
        - 读取：N/k * S（因为有k个副本，同一时间只能有N/k在读写）
        - 写入：N/k * S（因为要写k个副本）
      - 随机工作负载：
        - 读取：N * R（可以在所有磁盘上分配读取数据，从而获得完整的可用带宽）
        - 写入：N/k * S（因为要写k个副本）

#### RAID 4
- 奇偶校验：对于每一条数据，都添加了一个奇偶校验（parity）块，用于存储该条块的冗余信息
- 如何校验：典型的比如使用XOR函数：比如有n个1位二进制数，设p为这n个数的XOR，那么这n个数和p（共n+1个数）中一定有偶数个1；  
奇偶校验块由所有块的数据按位进行XOR得到，因此每一行（包括N-1个数据块和1个奇偶校验块）的数据中对应位1的个数之和一定是偶数  
如果有一个磁盘的数据丢失了，只需要考察别的磁盘，对于每一位根据1的个数来确定此磁盘上这一位是1还是0
- 评估
  - 容量：还行，N-1
  - 可靠性：一般，只容许1个磁盘故障，不容许更多
  - 性能：一般
    - 单个请求延迟：
      - 读取：与单个磁盘上的延迟相同
      - 写入：单个写入需要两次读取，两次写入读操作，读写操作都可以并行，所以延迟是单个磁盘延迟的两倍
    - 从稳态吞吐量的角度来看
      - 顺序工作负载：
        - 读取：(N-1) * S
        - 写入：(N-1) * S（奇偶校验磁盘能同时更新）
      - 随机工作负载：
        - 读取：(N-1) * R
        - 写入：R/2

> 随机工作负载写入： 
> 对于每次随机写入，都需要读取当前写入磁盘的旧块、奇偶校验磁盘，然后计算出新的奇偶校验数据，再写入奇偶校验磁盘，加上本身就有1次写入，所以一共2次读取2次写入（其中奇偶校验磁盘1次读取1次写入）  
> 因为奇偶校验磁盘不能实现任何的并行，所以它是瓶颈点（其他磁盘的读写是可以并行的）。每次写入都必须对奇偶校验磁盘进行1次读取和1次写入，这是最慢的一条线，所以吞吐量是R/2

#### RAID 5
- 旋转奇偶校验（奇偶校验磁盘依次轮换变化）
- 评估
  - 容量：还行，N-1
  - 可靠性：一般，只容许1个磁盘故障，不容许更多
  - 性能：稍好
    - 单个请求延迟：
      - 读取：与单个磁盘上的延迟相同
      - 写入：单个写入需要两次读取，两次写入读操作，读写操作都可以并行，所以延迟是单个磁盘延迟的两倍
    - 从稳态吞吐量的角度来看
      - 顺序工作负载：
        - 读取：(N-1) * S
        - 写入：(N-1) * S（奇偶校验磁盘能同时更新）
      - 随机工作负载：
        - 读取：N * R（可以利用所有的磁盘）
        - 写入：N/4 * R（因为奇偶校验磁盘不固定，所以可以并行进行。事实上，我们通常可以假设，如果有大量的随机请求，我们将能够保持所有磁盘均匀忙碌，4倍损失是由于每个RAID-5写入仍然产生总计4个I/O操作）
- RAID 5基本可以取代RAID 4


### 文件和目录
#### 创建文件
open 系统调用
#### 读写文件
> strace工具：跟踪程序做的系统调用
e.g. 使用cat命令读取foo文件（包含字符串"hello\n"）
使用strace工具跟踪：
```c
prompt> strace cat foo 
... 
open("foo", O_RDONLY|O_LARGEFILE) = 3 
read(3, "hello\n", 4096) = 6 
write(1, "hello\n", 6) = 6 
hello 
read(3, "", 4096) = 0 
close(3) = 0 
... 
prompt>
```
> open返回值为3：3为文件描述符，可能会不一样；但至少大于等于3：每个正在运行的进程都会打开3个文件：标准输入、标准输出、标准错误，对应的文件描述符为0，1，2
> read()的参数依次为：文件描述符、用于放置read()结果的缓冲区、缓冲区的大小，返回读取字节的数量
> write写入标准输出
> 再进行下一步的read，发现没有剩余字节，于是返回0
> 程序知道这意味着它已经读取了整个文件，因此程序调用close()，关闭文件

#### 不按顺序读写
lseek系统调用
#### 立即写入
fsync(int fd)
#### 重命名
通过mv命令完成，mv使用了系统调用rename(char * old, char * new)  
rename()调用提供了一个有趣的保证：它（通常）是一个原子调用，不论系统是否崩溃
#### 获取文件信息
使用 stat()或 fstat()系统调用
#### 删除文件
使用rm命令  
rm命令通过调用unlink函数删除文件  
unlink函数会取消链接文件  
每个文件都对应一个inode号，（硬）链接就是把这个inode号与人类可读的名称对应起来（使用link()操作，unlink()操作反之）  
引用计数：inode号链接的名称数量  
当文件系统取消链接文件时，它检查 inode号中的引用计数（reference count）。该引用计数（有时称为链接计数，link count）允许文件系统跟踪有多少不同的文件名已链接到这个inode。调用unlink()时，会删除人类可读的名称（正在删除的文件）与给定inode号之间的“链接”，并减少引用计数。只有当引用计数达到零时，文件系统才会释放inode和相关数据块，从而真正“删除”该文件  
可以用stat查看文件的引用计数
#### 创建目录
mkdir命令
mkdir()函数  
空目录有两个条目：一个引用自身的条目，一个引用其父目录的条目。前者称为“.”（点）目录，后者称为“..”（点-点）目录。
#### 读取目录
ls命令  
opendir()、readdir()、closedir()调用
#### 删除目录
rmdir命令  
rmdir()函数
#### 符号链接/软链接
其实是将链接指向文件的路径名作为链接文件的数据  
有可能造成悬空引用（删除原始文件会导致符号链接指向不再存在的路径名）
#### 创建并挂载文件系统
创建文件系统：mkfs工具  
作为输入，为该工具提供一个设备（例如磁盘分
区，例如/dev/sda1），一种文件系统类型（例如ext3）  
它就在该磁盘分区上写入一个空文件系统，从根目录开始  
挂载文件系统：mount()  
mount作用：以现有目录作为目标挂载点（mount point），本质上是将新的文件系统粘贴到目录树的这个点上  
mount 的美妙之处在于：它将所有文件系统统一到一棵树中，而不是拥有多个独立的文件系统，这让命名统一而且方便  

### VSFS文件系统实现
划分：
- 超级块（superblock），包含关于该特定文件系统的信息，包括例如文件系统中有多少个inode和数据块、inode 表的开始位置等等，可能还包括一些幻数，来标识文件系统类型。
- inode位图，inode bitmap
- 数据位图，data bitmap
> 位图是一种简单的结构：每个位用于指示相应的对象/块是空闲（0）还是正在使用（1）
- inode表，保存了一个磁盘上inode的数组
- 数据区域

#### inode
inode := index node  
在每个inode中，实际上是所有关于文件的信息：文件类型（例如，常规文件、目录等）、大小、分配给它的块数、保护信息（如谁拥有该文件以及谁可以访问它）、一些时间信息（包括文件创建、修改或上次访问的时间文件下），以及有关其数据块驻留在磁盘上的位置的信息（如某种类型的指针）。  
我们将所有关于文件的信息称为元数据（metadata）。

#### 多级索引
为了支持更大的文件，采用多级索引  
间接指针：不是指向包含用户数据的块，而是指向包含更多指针的块，每个指针指向用户数据。  
因此，inode可以有一些固定数量的直接指针和一个间接指针。如果文件变得足够大，则会分配一个间接块（来自磁盘的数据块区域），并将inode的间接指针设置为指向它。  
双重间接指针：添加另一个指向inode的指针，这个指针指的是一个包含间接块指针的块，每个间接块都包含指向数据块的指针
为了支持更大的文件也可以使用更多重指针  
这种不平衡树被称为指向文件块的多级索引（multi-level index）方法  
还有其他的如：基于范围的方法、基于链接的方法 

#### 目录
每个条目：
- inode号
- 总共长度（名称的总字节数加上所有的剩余空间）
- 字符串长度（名称的实际长度）
- 条目名称

> 每个目录有两个额外的条目：.（点）和..（点点）。点目录就是当前目录，而点点是父目录。

删除一个文件会在目录中留下空白空间，可以使用inode = 0来标记它  

通常文件系统将目录视为一个特殊类型的文件，因此目录文件也有一个inode，位于inode表的某处  
目录也可以使用其他数据结构来存储，比如B树

#### 空闲空间管理
VSFS中使用两个位图来实现

#### 访问
假设文件系统已经挂载，因此超级块已经在内存中。其他所有
内容（如 inode、目录）仍在磁盘上。
##### 读取
- 当发出一个open()调用时，文件系统先根据路径名找到对应的inode，因此要遍历路径名：从根开始（根目录的inode号通常为一个固定值，UNIX为2），由根目录的inode号找到根目录所在位置并读入（UNIX文件系统通常第一个就会读入inode号为2的块），然后依次向下遍历查询（目录的数据结构也许会改变查找的方式），直到找到所需的inode号
- 读取对应的inode
- 读取关于该文件的一些基本信息（权限信息、文件大小等等），进行权限检查
- 在每个进程的打开文件表中，为此进程分配一个文件描述符，并将它返回给用户
- 发出read()调用，从第一个块读取，根据inode找到这个块的位置，然后读取此块
- 更新inode，如访问时间；更新打开文件表中此文件描述符对应的文件偏移量，使其指向下一个块
- 继续读取。。。
- 读取完之后关闭文件：释放文件描述符

> 读取文件不需要访问位图

#### 写入
- write()调用
- 如果写入已有文件，就不需要分配新块，否则需要分配新块给新文件
- 写入新文件：需要读取数据位图和inode位图，决定分配哪些空间，还要更新数据位图和inode位图，还要写入新的inode、写入目录、更新父目录的inode等等
- 因此写入一个新文件可能需要很多次I/O

> 优化：缓存
> 比如将最近读取的文件放入缓存，以后读写不再需要I/O
> 现代系统通常采用动态划分（dynamic partitioning）方法。具体来说，许多现代操作系统将虚拟内存页面和文件系统页面集成到统一页面缓存中（unified page cache）在虚拟内存和文件系统之间更灵活地分配内存，具体取决于在给定时间哪种内存需要更多的内存
> 写缓冲（比如超过多少时间发生一次写入磁盘）、延迟写入、系统调度、懒惰写入也可以减少I/O的次数


### 局部性和快速文件系统
快速文件系统（Fast File System，FFS）  
FFS 将磁盘划分为一些分组，称为柱面组（cylinder group，而一些现代文件系统，如Linux ext2和ext3，就称它们为块组，即block group）  
FFS对于大文件的存储性能比较好  
FFS引入子块  
允许长文件名，引入符号链接

### 崩溃一致性：FSCK 和日志
由于崩溃，磁盘文件系统映像可能出现许多问题：在文件系统数据结构中可能存在不一致性、空间泄露、将垃圾数据返回给用户，等等。  
原因在于磁盘数据的更新不是原子性的操作，更新之间可能会发生崩溃或者断电。此类问题称为崩溃一致性问题。  

#### 解决方案 1：文件系统检查程序
在文件系统挂载之前调用一个程序检查此文件系统的正确性  
缺点：太慢了，因为要扫描整个磁盘

#### 解决方案 2：日志（或预写日志）
更新磁盘时，在覆写结构之前，首先写下一点小注记（在磁盘上的其他地方，在一个众所周知的位置），描述你将要做的事情。写下这个注记就是“预写”部分，我们把它写入一个结构，并组织成“日志”  
通过将注释写入磁盘，可以保证在更新（覆写）正在更新的结构期间发生崩溃时，能够返回并查看你所做的注记，然后重试。因此，你会在崩溃后准确知道要修复的内容（以及如何修复它），而不必扫描整个磁盘。  
日志中的内容可能包括：相关信息、inode表、数据块、位图等等  
三个阶段：
1. 日志写入：将事务的内容（包括 TxB、元数据和数据）写入日志，等待这些写入完成。
2. 日志提交：将事务提交块（包括 TxE）写入日志，等待写完成，事务被认为已提交。
3. 加检查点：将更新内容（元数据和数据）写入其最终的磁盘位置。

##### 批处理日志更新
比如在同一目录中创建多个文件，如果一个一个地更新就会浪费很多时间。因此可以将所有更新缓冲到全局事务中，当最后应该将这些块写入磁盘时（例如，在超时5s之后），会提交包含上述所有更新的单个全局事务。

##### 循环日志
为了解决日志爆满的问题  
方法：在加检查点之后再添加一步释放的操作
1. 日志写入：将事务的内容（包括 TxB 和更新内容）写入日志，等待这些写入完成。
2. 日志提交：将事务提交块（包括 TxE）写入日志，等待写完成，事务被认为已提交.
3. 加检查点：将更新内容写入其最终的磁盘位置。
4. 释放：一段时间后，通过更新日志超级块，在日志中标记该事务为空闲。

##### 元数据日志
原本日志（称为数据日志）会将用户数据同元数据同时写入日志，这样要写两遍用户数据，如果用户数据很大的话会带来巨大的额外开销  
而元数据日志不将用户数据写入日志  
1. 数据写入：将数据写入最终位置，等待完成（等待是可选的）。
2. 日志元数据写入：将开始块和元数据写入日志，等待写入完成。
3. 日志提交：将事务提交块（包括 TxE）写入日志，等待写完成，现在认为事务（包括数据）已提交（committed）。
4. 加检查点元数据：将元数据更新的内容写入文件系统中的最终位置。
5. 释放：稍后，在日志超级块中将事务标记为空闲

> 目录被认为是元数据

#### 解决方案 3：其他方法
- 软更新
- 写时复制
- 基于反向指针的一致性
- 乐观崩溃一致性

### 日志结构文件系统 LFS
intro
- 内存大小不断增长。随着内存越来越大，可以在内存中缓存更多数据。随着更多数据的缓存，磁盘流量将越来越多地由写入组成，因为读取将在缓存中进行处理。因此，文件系统性能很大程度上取决于写入性能。
- 随机I/O性能与顺序I/O性能之间存在巨大的差距，且不断扩大：传输带宽每年增加约50%～100%。寻道和旋转延迟成本下降得较慢，可能每年5%～10%。因此，如果能够以顺序方式使用磁盘，则可以获得巨大的性能优势，随着时间的推移而增长。
- 现有文件系统在许多常见工作负载上表现不佳。例如，FFS会执行大量写入，以创建大小为一个块的新文件：一个用于新的inode，一个用于更新inode位图，一个用于文件所在的目录数据块，一个用于目录inode以更新它，一个用于新数据块，它是新文件的一部分，另一个是数据位图，用于将数据块标记为已分配。因此，尽管FFS会将所有这些块放在同一个块组中，但FFS会导致许多短寻道和随后的旋转延迟，因此性能远远低于峰值顺序带宽。
- 文件系统不支持RAID。例如，RAID-4和RAID-5具有小写入问题（small-write problem），即对单个块的逻辑写入会导致4个物理I/O发生。现有的文件系统不会试图避免这种最坏情况的RAID写入行为。

LFS：  
写入磁盘时，LFS首先将所有更新（包括元数据）缓冲在内存段中。当段已满时，它会在一次长时间的顺序传输中写入磁盘，并传输到磁盘的未使用部分。LFS永远不会覆写现有数据，而是始终将段写入空闲位置。由于段很大，因此可以有效地使用磁盘，并且文件系统的性能接近其峰值。

#### 写入缓冲
LFS 一次写入的大块更新被称为段（segment）。  
在写入磁盘时，LFS 会缓冲内存段中的更新，然后将该段一次性写入磁盘。  
只要段足够大，这些写入就会很有效。

#### inode映射：imap
key：inode号  
value：inode磁盘地址  
LFS会将imap块也同其他新数据一起存放
> 为什么要搞个imap：因为LFS不会覆盖旧数据，因此最新版本的 inode会不断移动，不能取固定的块
> 还需要添加对目录的映射

#### 检查点区域 CR
如何很到 inode 映射，现在它的各个部分现在也分布在整个磁盘上？  
检查点区域包含指向最新的inode映射片段的指针（即地址），因此可以通过首先读取CR来很到inode映射片段。  
检查点区域仅定期更新（例如每30s左右），因此性能不会受到
影响。  

#### 读取文件过程
- CR
- imap
- inode
- 之后和传统文件系统类似。。。

#### 目录
因为目录只是<名称,inode号>映射的集合，所以目录结构与传统的UNIX文件系统基本相同

具体过程：
- 给定路径
- CR
- imap
- 目录
- 文件inode号
- imap
- 文件inode
- 数据块

递归更新问题：每当更新inode时，它在磁盘上的位置都会发生变化。如果我们不小心，这也会导致对指向该文件的目录的更新，然后必须更改该目录的父目录，依此类推，一路沿文件系统树向上。  
LFS避免了此问题：更改imap而不是目录

#### 垃圾收集
LFS清理程序按段工作，从而为后续写入清理出大块空间。  
LFS 清理程序定期读入许多旧的（部分使用的）段，确定哪些块在这些段中存在，然后写出一组新的段，只包含其中活着的块，从而释放旧块用于写入。具体来说，我们预期清理程序读取M个现有段，将其内容打包（compact）到N个新段（其中N < M），然后将N段写入磁盘的新位置。然后释放旧的M段，文件系统可以使用它们进行后续写入。

##### 确定块的死活
对于每个数据块 D，LFS 包括其inode号（它属于哪个文件）及其偏移量（这是该文件的哪一块）。该信息记录在一个数据结构中，位于段头部，称为段摘要块（segment summary block）。  
//因为CR是实时更新的，所以每次找到的都是最新的块，只需要比对一下最新块的地址是不是这个就行  
LFS走了一些捷径：当文件被截断或删除时，LFS 会增加其版本号（version number），并在 imap 中记录新版本号。通过在磁盘上的段中记录版本号，LFS可以简单地通过将磁盘版本号与imap中的版本号进行比较，跳过上述较长的检查，从而避免额外的读取。

#### 何时清理
还在研究，是LFS争议的焦点

#### 崩溃恢复和日志
- 写入CR时崩溃：为了确保CR更新以原子方式发生，LFS实际上保留了两个CR，每个位于磁盘的一端，并交替写入它们。当使用最新的指向 inode映射和其他信息的指针更新 CR时，LFS还实现了一个谨慎的协议。具体来说，它首先写出一个头（带有时间戳），然后写出CR的主体，然后最后写出最后一部分（也带有时间戳）。如果系统在CR更新期间崩溃，LFS可以通过查看一对不一致的时间戳来检测到这一点。LFS将始终选择使用具有一致时间戳的最新CR，从而实现CR的一致更新
- 写入段时崩溃：LFS可以通过简单地读取CR、它指向的imap片段以及后续文件和目录，从而轻松地恢复


### 数据完整性和保护
#### 常见的两种类型的故障
- 潜在扇区错误（Latent-Sector Errors，LSE）：例如，如果磁头由于某种原因接触到表面（磁头碰撞，head crash，在正常操作期间不应发生的情况），则可能会讹误表面，使得数据位不可读。宇宙射线也会导致数据位翻转，使内容不正确。
- 块讹误（block corruption）：例如，有缺陷的磁盘固件可能会将块写入错误的位置。类似地，当一个块通过有故障的总线从主机传输到磁盘时，它可能会讹误。由此产生的讹误数据会存入磁盘，但它不是客户所希望的。这些类型的故障特别隐蔽，因为它们是无声的故障（silent fault）。返回故障数据时，磁盘没有报告问题。

#### 处理潜在的扇区错误
- 利用冗余机制，访问备用副本  
- 或者利奇偶校验位重建该块

#### 检测讹误：校验和
校验和就是一个函数的结果，该函数以一块数据（例如 4KB 块）作为输入，并计算这段数据的函数，产生数据内容的小概要（比如 4 字节或 8 字节）。此摘要称为校验和。这种计算的目的在于，让系统将校验和与数据一起存储，然后在访问时确认数据的当前校验和与原始存储值匹配，从而检测数据是否以某种方式被破坏或改变。

##### 常见的校验和函数
- XOR
- 二进制补码加法，忽略溢出
- Fletcher校验和
- 循环冗余校验（CRC）

#### 错误的写入
- 写入错误的地址
- 写入错误的磁盘

解决：在每个校验和中添加更多信息：  
添加物理标识符（Physical Identifier，物理ID），如磁盘号，块号

> 可以从磁盘格式看到，磁盘上现在有相当多的冗余

#### 丢失的写入
- 写入验证
- 写入后读取
- 在系统的其他位置添加校验和

#### 擦净
定期读取系统的每个块，并检查校验和是否仍然有效，磁盘系统可以减少某个数据项的所有副本都被破坏的可能性。典型的系统每晚或每周安排扫描。

### 分布式系统

#### 通信
##### 通信本身是不可靠的
> 几乎在所有情况下，将通信视为根本不可靠的活动是很好的。位讹误、关闭或无效的链接和机器，以及缺少传入数据包的缓冲区空间，都会导致相同的结果：数据包有时无法到达目的地。为了在这种不可靠的网络上建立可靠的服务，我们必须考虑能够应对数据包丢失的技术。
> 数据包丢失或损坏的原因很多。有时，在传输过程中，由于电气或其他类似问题，某些位会被翻转。有时，系统中的某个元素（例如网络链接或数据包路由器，甚至远程主机）会以某种方式损坏，或以其他方式无法正常工作。
> 丢包：数据包丢失

##### 可靠的通信层
###### 超时/重试（timeout/retry）
- 确认（acknowledgment，ack）：发送方向接收方发送消息，接收方然后发回短消息确认收到。
- 超时（timeout）： 当发送方发送消息时，发送方现在将计时器设置为在一段时间后关闭。如果在此时间内未收到确认，则发送方断定该消息已丢失。
- 重试（retry）：再次发送相同的消息
- 问题：如果丢失的是确认信息，那么发送方就会发送多次数据，那么接收方就会接受重复多个数据包，造成负担；最好保证接受方每个消息只接收一次
- 解决：顺序计数器（sequence counter）：发送方和接收方维护一个相同的起始计数器值，每次消息都和计数器的值一起发送，成功发送消息后发送方递增计数器的值（因此计数器的值可以当作消息的ID）；接受方计数器的值为它预期接收到的消息ID的值，如果接受到的消息匹配，那么接受方也将计数器递增，并等待下一条消息；如果确认信息丢失，那么发送方将重新发送信息，此时接收方计数器的值比发送方的大，因此接收器知道自己已经接收了该消息，它会确认该消息，但不会将其传递给应用程序。
- 最常用的可靠通信层称为TCP/IP，或简称为TCP。TCP比上面描述的要复杂得多，包括处理网络拥塞的机制，多个未完成的请求，以及数百个其他的小调整和优化

##### 通信抽象
###### 分布式共享内存 DSM
分布式共享内存（Distributed Shared Memory，DSM）系统使不同机器上的进程能够共享一个大的虚拟地址空间。这种抽象将分布式计算变成貌似多线程应用程序。唯一的区别是这些线程在不同的机器上运行，而不是在同一台机器上的不同处理器上。
访问页面时，可能会发生两种情况：
- 在第一种（最佳）情况下，页面已经是机器上的本地页面，因此可以快速获取数据。
- 在第二种情况下，页面目前在其他机器上。发生页面错误，页面错误处理程序将消息发送到其他计算机以获取页面，将其装入请求进程的页表中，然后继续执行。
- 问题：
  - 处理故障：一台机器出西现故障的话会连锁导致其他机器出现故障（因为数据可能分布在不同的机器上）；
  - 性能：访问内存可能变得昂贵

###### 远程过程调用（RPC）
目标：使在远程机器上执行代码的过程像调用本地函数一样简单直接。  
因此，对于客户端来说，进行一个过程调用，并在一段时间后返回结果。服务器只是定义了一些它希望导出的例程  
RPC系统通常有两部分：
- 存根生成器（stub generator，有时称为协议编译器，protocol compiler）：输入是服务器希望导出到客户端的一组调用，存根生成器接受这样的接口，并生成一些不同的代码片段。对于客户端，生成客户端存根（client stub），其中包含接口中指定的每个函数。在内部，客户端存根中的每个函数都执行远程过程调用所需的所有工作。对于客户端，代码只是作为函数调用出现。
> 相当于作为中间桥梁，把客户端需要的函数转变为远程调用的函数，把本地调用转化为远程调用（所以也叫“协议编译器”）
创建消息缓冲区。消息缓冲区通常只是某种大小的连续字节数组。
  - 将所需信息打包到消息缓冲区中。该信息包括要调用的函数的某种标识符，以及函数所需的所有参数。将所有这些信息放入单个连续缓冲区的过程，有时被称为参数的封送处理（marshaling）或消息的序列化（serialization）。
  - 将消息发送到目标RPC服务器。与RPC服务器的通信，以及使其正常运行所需的所有细节，都由RPC运行时库处理。
  - 等待回复。由于函数调用通常是同步的（synchronous），因此调用将等待其完成。
  - 解包返回代码和其他参数。如果函数只返回一个返回码，那么这个过程很简单。但是，较复杂的函数可能会返回更复杂的结果（例如，列表），因此存根可能也需要对它们解包。此步骤也称为解封送处理（unmarshaling）或反序列化（deserialization）。
  - 返回调用者。最后，只需从客户端存根返回到客户端代码。

对于服务器，也会生成代码。在服务器上执行的步骤如下：
  - 解包消息。此步骤称为解封送处理（unmarshaling）或反序列化（deserialization），将信息从传入消息中取出。提取函数标识符和参数。
  - 调用实际函数。终于，我们到了实际执行远程函数的地方。RPC运行时调用ID指定的函数，并传入所需的参数。
  - 打包结果。返回参数被封送处理，放入一个回复缓冲区。
  - 发送回复。回复最终被发送给调用者。
> 服务器类似于一台电脑
- 运行时库（run-time library）：运行时库处理RPC系统中的大部分繁重工作。这里处理大多数性能和可靠性问题。比如要知道和谁在通信（要知道所需RPC服务的机器的主机名或IP地址，以及它正在使用的端口号），要将数据包从系统中的任何其他机器路由到特定地址。

### Sun的网络文件系统（NFS）
- 无状态（stateless）协议  
- 服务器不会追踪每个客户端发生的事情。  
- 每个客户端操作都包含完成请求所需的所有信息
- 出错就重试
- 文件句柄：包括卷标识符、inode号和世代号：卷标识符通知服务器，请求指向哪个文件系统（NFS服务器可以导出多个文件系统）。inode号告诉服务器，请求访问该分区中的哪个文件。最后，复用inode号时需要世代号。通过在复用inode号时递增世代号，服务器确保具有旧文件句柄的客户端不会意外地访问新分配的文件。
- 幂等操作：如果操作执行多次的效果与执行一次的效果相同，该操作就是幂等的
- NFS 中崩溃恢复的核心在于，大多数常见操作具有幂等性。
> LOOKUP和READ请求是简单幂等的，因为它们只从文件服务器读取信息而不更新它。更有趣的是，WRITE请求也是幂等的。例如，如果WRITE失败，客户端可以简单地重试它。WRITE消息包含数据、计数和（重要的）写入数据的确切偏移量。因此，可以重复多次写入，因为多次写入的结果与单次的结果相同。
- 提高性能：客户端缓存：缓存到客户端的本地内存
  - 缓存一致性问题：多个客户端访问同一个服务器，更新同一块数据时可能出现缓存一致性问题
  - 解决：
    - “关闭时刷新”：具体来说，当应用程序写入文件并随后关闭文件时，客户端将所有更新（即缓存中的脏页面）刷新到服务器。通过关闭时刷新的一致性，NFS 可确保后续从另一个节点打开文件，会看到最新的文件版本。
    - 访问文件时先查看属性，如果文件修改的时间晚于文件提取到客户端缓存的时间（即过时了），那么让文件无效，同时重新向服务器获取文件的最新版本
- 服务器端写缓冲：在强制写入稳定存储（即磁盘或某些其他持久设备）之前，NFS服务器绝对不会对WRITE协议请求返回成功（因为崩溃可能让内存中的内容丢失）。

### Andrew文件系统（AFS）
- 在访问文件的客户端计算机的本地磁盘上进行全文件缓存。 open()文件时，将从服务器获取整个文件，并存储在本地磁盘上的文件中。后续应用程序read()和write()操作被重定向到存储文件的本地文件系统。因此，这些操作不需要网络通信，速度很快。最后，在close()时，文件（如果已被修改）被写回服务器。
- 回调（callback）：当客户端缓存的文件被修改时，服务器将通知客户端
> 类似于中断，NFS的处理方法类似轮询
- 文件标识符（File Identifier，FID）：类似于NFS文件句柄，用于标识文件，以替代路径名。AFS中的FID包括卷标识符、文件标识符和“全局唯一标识符”（用于在删除文件时复用卷和文件 ID）。
- 如果客户端访问文件/home/remzi/notes.txt，那么会一级一级地访问home、remzi目录，并把它们都缓存到本地磁盘中，并在home、remzi、notes.txt中设置回调；这样的好处是避免让服务器一级一级地查找路径，带来大量的时间损失
- 如果文件已经过时，后续访问该文件时需要重新从客户端获取
- “最后写入者胜出”方法：最后更新的文件将保留在服务器上。
- 处理崩溃是大麻烦



























